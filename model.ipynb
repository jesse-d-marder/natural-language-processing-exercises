{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2e0f16-287e-4cc6-b5b8-74ef7882c7e1",
   "metadata": {},
   "source": [
    "Modeling exercises for NLP. What other types of algorithms can be used? How do models compare when training on term frequency data alone instead of TF-IDF values alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eb53e2b8-0865-43d2-b95e-08407c786786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from env import get_db_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650cb580-3bf1-4eb0-a88a-f7a7e9e50118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM spam\", get_db_url(\"spam_db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04230b4-7c2b-41fc-8744-ffb75255735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "train, validate, test = prepare.train_validate_test_split(df, target = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d56d07-3536-4c51-8131-d739f225e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.95%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                2700    94\n",
      "spam                  1   324\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      2701\n",
      "        spam       1.00      0.78      0.87       418\n",
      "\n",
      "    accuracy                           0.97      3119\n",
      "   macro avg       0.98      0.89      0.93      3119\n",
      "weighted avg       0.97      0.97      0.97      3119\n",
      "\n",
      "Accuracy: 95.67%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                1158    58\n",
      "spam                  0   122\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98      1158\n",
      "        spam       1.00      0.68      0.81       180\n",
      "\n",
      "    accuracy                           0.96      1338\n",
      "   macro avg       0.98      0.84      0.89      1338\n",
      "weighted avg       0.96      0.96      0.95      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidf.fit_transform(train.text)\n",
    "X_validate = tfidf.transform(validate.text)\n",
    "X_test = tfidf.transform(test.text)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_tfidf.predicted_log_reg, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_tfidf.predicted_log_reg, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_log_reg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1b324-dfb6-4bad-89f9-2e0233a0ea7c",
   "metadata": {},
   "source": [
    "Great accuracy here is misleading - the model never actually predicts spam! This means the model would send every message to the inbox which is not very useful but is better than sending ham to the spam box. This is likely happening because the data set is quite unbalanced so the model has few chances to learn from a spam instance. We'll optimize for precision and be ok being a little annoyed by the spam that makes it in the inbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5041e066-da55-4105-8135-9e7975d92d5f",
   "metadata": {},
   "source": [
    "Will try using a Random Forest Classifier with the tf-idf scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7058e910-0fd7-4b0a-9adf-35f8af995a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 40).fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_rf'] = rf.predict(X_train)\n",
    "validate_results_tfidf['predicted_rf'] = rf.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d79f9e3-544b-46e6-b371-7777ff097ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.07%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           2701    29\n",
      "spam             0   389\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      2701\n",
      "        spam       1.00      0.93      0.96       418\n",
      "\n",
      "    accuracy                           0.99      3119\n",
      "   macro avg       0.99      0.97      0.98      3119\n",
      "weighted avg       0.99      0.99      0.99      3119\n",
      "\n",
      "Accuracy: 96.49%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           1158    47\n",
      "spam             0   133\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1158\n",
      "        spam       1.00      0.74      0.85       180\n",
      "\n",
      "    accuracy                           0.96      1338\n",
      "   macro avg       0.98      0.87      0.91      1338\n",
      "weighted avg       0.97      0.96      0.96      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_rf)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_tfidf.predicted_rf, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_rf))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_rf)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_tfidf.predicted_rf, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25799e1e-cb40-4d09-9463-8bf8144393a0",
   "metadata": {},
   "source": [
    "Random Forest with max depth of 40 does fairly well accuracy wise and precision is 1 once again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99077dbe-9699-4278-bc54-c5d6bb8b2c85",
   "metadata": {},
   "source": [
    "Will try using count vectorizer data alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b37b51-4bd9-403b-b40c-899782314505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.71%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                2701     9\n",
      "spam                  0   409\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      2701\n",
      "        spam       1.00      0.98      0.99       418\n",
      "\n",
      "    accuracy                           1.00      3119\n",
      "   macro avg       1.00      0.99      0.99      3119\n",
      "weighted avg       1.00      1.00      1.00      3119\n",
      "\n",
      "Accuracy: 97.38%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                1157    34\n",
      "spam                  1   146\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      1158\n",
      "        spam       0.99      0.81      0.89       180\n",
      "\n",
      "    accuracy                           0.97      1338\n",
      "   macro avg       0.98      0.91      0.94      1338\n",
      "weighted avg       0.97      0.97      0.97      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.text)\n",
    "X_validate = cv.transform(validate.text)\n",
    "X_test = cv.transform(test.text)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_cv.predicted_log_reg, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_cv.predicted_log_reg, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35521504-2f03-446e-a47e-5197a8a1c8b4",
   "metadata": {},
   "source": [
    "Better performance for all metrics! Will try Random Forest with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "036423c3-8b05-42d9-8e57-d642578ff98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.91%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           2701    34\n",
      "spam             0   384\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      2701\n",
      "        spam       1.00      0.92      0.96       418\n",
      "\n",
      "    accuracy                           0.99      3119\n",
      "   macro avg       0.99      0.96      0.98      3119\n",
      "weighted avg       0.99      0.99      0.99      3119\n",
      "\n",
      "Accuracy: 96.11%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           1158    52\n",
      "spam             0   128\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1158\n",
      "        spam       1.00      0.71      0.83       180\n",
      "\n",
      "    accuracy                           0.96      1338\n",
      "   macro avg       0.98      0.86      0.90      1338\n",
      "weighted avg       0.96      0.96      0.96      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.text)\n",
    "X_validate = cv.transform(validate.text)\n",
    "X_test = cv.transform(test.text)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=40).fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_rf'] = rf.predict(X_train)\n",
    "validate_results_cv['predicted_rf'] = rf.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_rf)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_cv.predicted_rf, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_rf))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_rf)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_cv.predicted_rf, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_rf))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d9d01-68be-4ed8-882e-64df86dbe5da",
   "metadata": {},
   "source": [
    "Not as good performance as the Logistic Regression model. Slightly worse performance than tf-idf data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166d994-a2d4-4078-95df-7b74eac2cc48",
   "metadata": {},
   "source": [
    "Does it make a difference if the data is cleaned/lemmatized first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257b2447-487e-42a1-838b-849cdbab2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_lem_df = df.copy()\n",
    "clean_and_lem_df['lem'] = df.text.apply(prepare.basic_clean).apply(prepare.tokenize).apply(prepare.lemmatize).apply(prepare.remove_stopwords,\n",
    "                                                       extra_words = [],\n",
    "                                                       exclude_words = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aef2cb9-838c-48fc-804c-7608751d264f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label                                               text\n",
       "0   0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   1   ham                      Ok lar... Joking wif u oni...\n",
       "2   2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   3   ham  U dun say so early hor... U c already then say...\n",
       "4   4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e61e8ac-4d24-416e-8a84-593ea0a20b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah ' think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label                                               text  \\\n",
       "0   0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   1   ham                      Ok lar... Joking wif u oni...   \n",
       "2   2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   3   ham  U dun say so early hor... U c already then say...   \n",
       "4   4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                 lem  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4              nah ' think go usf life around though  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_lem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eebf1a47-ab19-4436-be10-888a4e58fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.train_validate_test_split(clean_and_lem_df, target = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c039e21a-5cbb-49e9-aac4-2c4820b0a71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.36%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                2700    19\n",
      "spam                  1   399\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      1.00      2701\n",
      "        spam       1.00      0.95      0.98       418\n",
      "\n",
      "    accuracy                           0.99      3119\n",
      "   macro avg       1.00      0.98      0.99      3119\n",
      "weighted avg       0.99      0.99      0.99      3119\n",
      "\n",
      "Accuracy: 97.01%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                1157    39\n",
      "spam                  1   141\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1158\n",
      "        spam       0.99      0.78      0.88       180\n",
      "\n",
      "    accuracy                           0.97      1338\n",
      "   macro avg       0.98      0.89      0.93      1338\n",
      "weighted avg       0.97      0.97      0.97      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.lem)\n",
    "X_validate = cv.transform(validate.lem)\n",
    "X_test = cv.transform(test.lem)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_cv.predicted_log_reg, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_cv.predicted_log_reg, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea8e30-0e53-4e01-b91d-f2d1977c3b25",
   "metadata": {},
   "source": [
    "Slightly worse performance but still quite good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab38f7-54ed-45ea-8d41-39e25e46ec4d",
   "metadata": {},
   "source": [
    "# Classification of category with news data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257b72a-d1ed-4506-9075-b70435b00c20",
   "metadata": {},
   "source": [
    "Import news data and try different modeling techniques for determining category of news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f6a98d6-4551-4bef-b713-e3d31249116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing from csv\n"
     ]
    }
   ],
   "source": [
    "news = prepare.create_prepared_news_df()\n",
    "target = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b60f52a-3474-4d39-bad8-fa9f364ba026",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.train_validate_test_split(news, target = 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9d48a-6033-4f4e-9e41-7252200276f7",
   "metadata": {},
   "source": [
    "Simple term frequency with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffe8e680-3399-45dd-8f36-d8c59d315f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.88      1.00      0.93        14\n",
      "     business       1.00      0.79      0.88        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "        hatke       1.00      1.00      1.00        14\n",
      "miscellaneous       0.93      1.00      0.97        14\n",
      "     national       1.00      1.00      1.00        14\n",
      "     politics       0.93      1.00      0.97        14\n",
      "      science       0.93      1.00      0.97        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "      startup       0.92      0.86      0.89        14\n",
      "   technology       0.92      0.85      0.88        13\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.95       167\n",
      "    macro avg       0.95      0.95      0.95       167\n",
      " weighted avg       0.95      0.95      0.95       167\n",
      "\n",
      "Accuracy: 55.56%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.67      0.67      0.67         6\n",
      "     business       0.40      0.33      0.36         6\n",
      "entertainment       0.75      0.50      0.60         6\n",
      "        hatke       0.57      0.67      0.62         6\n",
      "miscellaneous       0.22      0.33      0.27         6\n",
      "     national       0.50      0.50      0.50         6\n",
      "     politics       0.57      0.67      0.62         6\n",
      "      science       0.75      0.50      0.60         6\n",
      "       sports       0.75      1.00      0.86         6\n",
      "      startup       0.40      0.33      0.36         6\n",
      "   technology       0.50      0.17      0.25         6\n",
      "        world       0.67      1.00      0.80         6\n",
      "\n",
      "     accuracy                           0.56        72\n",
      "    macro avg       0.56      0.56      0.54        72\n",
      " weighted avg       0.56      0.56      0.54        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.lemmatized)\n",
    "X_validate = cv.transform(validate.lemmatized)\n",
    "X_test = cv.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg)))\n",
    "# print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_cv.predicted_log_reg, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg)))\n",
    "# print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_cv.predicted_log_reg, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aae729-84e7-41a2-a055-00116cd21c35",
   "metadata": {},
   "source": [
    "Pretty horrible job of predicting category of news based on Logistic Regression and count vectorizer. Overfit. Will try with bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37324189-1cf7-475b-9c63-2257b60746c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.93      0.93      0.93        14\n",
      "     business       0.92      0.86      0.89        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "        hatke       1.00      1.00      1.00        14\n",
      "miscellaneous       0.93      1.00      0.97        14\n",
      "     national       1.00      1.00      1.00        14\n",
      "     politics       0.93      1.00      0.97        14\n",
      "      science       0.93      1.00      0.97        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "      startup       0.87      0.93      0.90        14\n",
      "   technology       1.00      0.77      0.87        13\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.95       167\n",
      "    macro avg       0.95      0.95      0.95       167\n",
      " weighted avg       0.95      0.95      0.95       167\n",
      "\n",
      "Accuracy: 30.56%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.67      0.33      0.44         6\n",
      "     business       0.40      0.33      0.36         6\n",
      "entertainment       0.33      0.17      0.22         6\n",
      "        hatke       1.00      0.17      0.29         6\n",
      "miscellaneous       0.06      0.33      0.11         6\n",
      "     national       0.00      0.00      0.00         6\n",
      "     politics       0.43      0.50      0.46         6\n",
      "      science       1.00      0.17      0.29         6\n",
      "       sports       0.75      0.50      0.60         6\n",
      "      startup       1.00      0.17      0.29         6\n",
      "   technology       0.50      0.33      0.40         6\n",
      "        world       0.50      0.67      0.57         6\n",
      "\n",
      "     accuracy                           0.31        72\n",
      "    macro avg       0.55      0.31      0.34        72\n",
      " weighted avg       0.55      0.31      0.34        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_train = cv.fit_transform(train.lemmatized)\n",
    "X_validate = cv.transform(validate.lemmatized)\n",
    "X_test = cv.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg_bigrams'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg_bigrams'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg_bigrams)))\n",
    "# print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_cv.predicted_log_reg_bigrams, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg_bigrams))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg_bigrams)))\n",
    "# print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_cv.predicted_log_reg_bigrams, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg_bigrams))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4d25b-519a-45d2-981f-950382c9b79b",
   "metadata": {},
   "source": [
    "Even worse!!! Will try with naive Bayes without bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3b04c0d-dadf-4cf2-9b2d-0960ad064a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.88      1.00      0.93        14\n",
      "     business       1.00      0.79      0.88        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "        hatke       1.00      1.00      1.00        14\n",
      "miscellaneous       1.00      0.93      0.96        14\n",
      "     national       1.00      1.00      1.00        14\n",
      "     politics       0.93      1.00      0.97        14\n",
      "      science       0.93      1.00      0.97        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "      startup       0.87      0.93      0.90        14\n",
      "   technology       1.00      0.77      0.87        13\n",
      "        world       0.88      1.00      0.93        14\n",
      "\n",
      "     accuracy                           0.95       167\n",
      "    macro avg       0.96      0.95      0.95       167\n",
      " weighted avg       0.96      0.95      0.95       167\n",
      "\n",
      "Accuracy: 51.39%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.57      0.67      0.62         6\n",
      "     business       0.40      0.33      0.36         6\n",
      "entertainment       0.67      0.33      0.44         6\n",
      "        hatke       0.80      0.67      0.73         6\n",
      "miscellaneous       0.00      0.00      0.00         6\n",
      "     national       0.50      0.50      0.50         6\n",
      "     politics       0.40      0.67      0.50         6\n",
      "      science       0.75      0.50      0.60         6\n",
      "       sports       0.75      1.00      0.86         6\n",
      "      startup       0.40      0.33      0.36         6\n",
      "   technology       0.33      0.17      0.22         6\n",
      "        world       0.55      1.00      0.71         6\n",
      "\n",
      "     accuracy                           0.51        72\n",
      "    macro avg       0.51      0.51      0.49        72\n",
      " weighted avg       0.51      0.51      0.49        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.lemmatized)\n",
    "X_validate = cv.transform(validate.lemmatized)\n",
    "X_test = cv.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_cv.predicted_nb, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_cv.predicted_nb, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_nb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448340b6-2be9-4f0b-be8b-d7bfc7f9eee1",
   "metadata": {},
   "source": [
    "Inferior to Logistic regression. Will try with tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed668ac2-fa57-4eba-a0bc-a180425cae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.88      1.00      0.93        14\n",
      "     business       0.92      0.86      0.89        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "        hatke       1.00      1.00      1.00        14\n",
      "miscellaneous       1.00      0.93      0.96        14\n",
      "     national       1.00      1.00      1.00        14\n",
      "     politics       0.93      1.00      0.97        14\n",
      "      science       0.93      1.00      0.97        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "      startup       0.87      0.93      0.90        14\n",
      "   technology       1.00      0.77      0.87        13\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.95       167\n",
      "    macro avg       0.95      0.95      0.95       167\n",
      " weighted avg       0.95      0.95      0.95       167\n",
      "\n",
      "Accuracy: 55.56%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.80      0.67      0.73         6\n",
      "     business       0.43      0.50      0.46         6\n",
      "entertainment       0.60      0.50      0.55         6\n",
      "        hatke       0.80      0.67      0.73         6\n",
      "miscellaneous       0.00      0.00      0.00         6\n",
      "     national       0.43      0.50      0.46         6\n",
      "     politics       0.50      0.67      0.57         6\n",
      "      science       0.80      0.67      0.73         6\n",
      "       sports       0.75      1.00      0.86         6\n",
      "      startup       0.33      0.33      0.33         6\n",
      "   technology       0.33      0.17      0.22         6\n",
      "        world       0.75      1.00      0.86         6\n",
      "\n",
      "     accuracy                           0.56        72\n",
      "    macro avg       0.54      0.56      0.54        72\n",
      " weighted avg       0.54      0.56      0.54        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c23d9d-d450-4875-91cd-10b345734fa7",
   "metadata": {},
   "source": [
    "Not great but slight improvement over term frequency, same performance as logistic regression. Looks like severe overfitting. Will try with bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a01ea9d-a5ba-4ab7-a9f3-56823e656fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.88      1.00      0.93        14\n",
      "     business       1.00      0.79      0.88        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "        hatke       1.00      1.00      1.00        14\n",
      "miscellaneous       0.93      1.00      0.97        14\n",
      "     national       1.00      1.00      1.00        14\n",
      "     politics       0.93      1.00      0.97        14\n",
      "      science       0.93      1.00      0.97        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "      startup       0.87      0.93      0.90        14\n",
      "   technology       1.00      0.77      0.87        13\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.95       167\n",
      "    macro avg       0.96      0.95      0.95       167\n",
      " weighted avg       0.96      0.95      0.95       167\n",
      "\n",
      "Accuracy: 43.06%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.26      0.83      0.40         6\n",
      "     business       0.40      0.33      0.36         6\n",
      "entertainment       0.50      0.17      0.25         6\n",
      "        hatke       0.67      0.33      0.44         6\n",
      "miscellaneous       0.00      0.00      0.00         6\n",
      "     national       0.25      0.17      0.20         6\n",
      "     politics       0.38      0.50      0.43         6\n",
      "      science       0.75      0.50      0.60         6\n",
      "       sports       0.71      0.83      0.77         6\n",
      "      startup       1.00      0.33      0.50         6\n",
      "   technology       0.50      0.33      0.40         6\n",
      "        world       0.45      0.83      0.59         6\n",
      "\n",
      "     accuracy                           0.43        72\n",
      "    macro avg       0.49      0.43      0.41        72\n",
      " weighted avg       0.49      0.43      0.41        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f17159-b6ef-40a5-919e-909ac39701cf",
   "metadata": {},
   "source": [
    "Bigrams don't help at all. Will combine words with bigrams to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9650833-0977-44ca-9538-e473ee5b17f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.21%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.88      1.00      0.93        14\n",
      "     business       0.92      0.86      0.89        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "        hatke       1.00      1.00      1.00        14\n",
      "miscellaneous       1.00      0.93      0.96        14\n",
      "     national       1.00      1.00      1.00        14\n",
      "     politics       0.93      1.00      0.97        14\n",
      "      science       0.93      1.00      0.97        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "      startup       0.87      0.93      0.90        14\n",
      "   technology       1.00      0.77      0.87        13\n",
      "        world       0.93      0.93      0.93        14\n",
      "\n",
      "     accuracy                           0.95       167\n",
      "    macro avg       0.95      0.95      0.95       167\n",
      " weighted avg       0.95      0.95      0.95       167\n",
      "\n",
      "Accuracy: 55.56%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.80      0.67      0.73         6\n",
      "     business       0.43      0.50      0.46         6\n",
      "entertainment       0.60      0.50      0.55         6\n",
      "        hatke       0.80      0.67      0.73         6\n",
      "miscellaneous       0.00      0.00      0.00         6\n",
      "     national       0.50      0.50      0.50         6\n",
      "     politics       0.50      0.67      0.57         6\n",
      "      science       0.80      0.67      0.73         6\n",
      "       sports       0.75      1.00      0.86         6\n",
      "      startup       0.33      0.33      0.33         6\n",
      "   technology       0.33      0.17      0.22         6\n",
      "        world       0.67      1.00      0.80         6\n",
      "\n",
      "     accuracy                           0.56        72\n",
      "    macro avg       0.54      0.56      0.54        72\n",
      " weighted avg       0.54      0.56      0.54        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf9dea-8ff3-48b9-823d-fad75ab86e7f",
   "metadata": {},
   "source": [
    "Same performance as just words and tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578d934-5023-49ee-9ab6-c2e1f36648ea",
   "metadata": {},
   "source": [
    "### Overall performance is pretty awful for classifying between all categories. Severe overfitting from train to validate. Perhaps attempting to classify fewer categories would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9df1fd14-0e5e-4822-b234-789f1646bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.train_validate_test_split(news[news.category.isin(['sports','world','business'])], target = 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ae22860-64f1-4cc3-b399-121857b9c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       1.00      1.00      1.00        14\n",
      "      sports       1.00      1.00      1.00        14\n",
      "       world       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "Accuracy: 77.78%\n",
      "---\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.62      0.83      0.71         6\n",
      "      sports       0.83      0.83      0.83         6\n",
      "       world       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.82      0.78      0.78        18\n",
      "weighted avg       0.82      0.78      0.78        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c9934-ee64-48d3-b389-526e9800c6c8",
   "metadata": {},
   "source": [
    "A lot better performance when classifying fewer categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aaa62e-0588-4f9a-9862-14d6a748193a",
   "metadata": {},
   "source": [
    "### Put into a function which returns classification reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d7bcdd41-0cc5-4220-9198-c15b87966024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_words(vectorizer, class_model, ngrams_range_value, train, validate, target, print_results = True):\n",
    "    \"\"\"Performs classification modeling of lemmatized data. Outputs (and returns) classification reports for train and validate/test.\n",
    "    \n",
    "    vectorizer: the type of feature extraction method, such as Count Vectorizer or tf-idf\n",
    "    class_model: the classification model to use\n",
    "    ngrams_range_value: whether to use unigram, bigrams, etc. for the feature extraction\n",
    "    train and test sets as well as the target variable\"\"\"\n",
    "    \n",
    "    feature_extraction_method = vectorizer(ngram_range=ngrams_range_value)\n",
    "\n",
    "    X_train = feature_extraction_method.fit_transform(train.lemmatized)\n",
    "    X_validate = feature_extraction_method.transform(validate.lemmatized)\n",
    "    X_test = feature_extraction_method.transform(test.lemmatized)\n",
    "    y_train = train[target]\n",
    "    y_validate = validate[target]\n",
    "    # y_test = test[target]\n",
    "\n",
    "    train_results=pd.DataFrame(dict(actual = y_train))\n",
    "    validate_results = pd.DataFrame(dict(actual = y_validate))\n",
    "    # test_results = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "    model_to_use = class_model.fit(X_train, y_train)\n",
    "\n",
    "    train_results['predicted'] = model_to_use.predict(X_train)\n",
    "    validate_results['predicted'] = model_to_use.predict(X_validate)\n",
    "    # test_results['predicted'] = model_to_use.predict(X_test)\n",
    "    train_class_report = classification_report(train_results.actual, train_results.predicted, output_dict = True)\n",
    "    validate_class_report = classification_report(validate_results.actual, validate_results.predicted,output_dict=True)\n",
    "    if print_results:\n",
    "        print('Accuracy: {:.2%}'.format(accuracy_score(train_results.actual, train_results.predicted)))\n",
    "        print('---')\n",
    "        # print('Train Confusion Matrix')\n",
    "        # print(pd.crosstab(train_results_tfidf.predicted, train_results_tfidf.actual))\n",
    "        print('---')\n",
    "        print(pd.DataFrame(train_class_report))\n",
    "\n",
    "\n",
    "        print('Accuracy: {:.2%}'.format(accuracy_score(validate_results.actual, validate_results.predicted)))\n",
    "        print('---')\n",
    "        # print('Validate Confusion Matrix')\n",
    "        # print(pd.crosstab(validate_results_tfidf.predicted, validate_results_tfidf.actual))\n",
    "        print('---')\n",
    "        print(pd.DataFrame(validate_class_report))\n",
    "    \n",
    "    return train_class_report, validate_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aef44de4-4019-4c3e-9cc9-57fe5728c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  sports  world  accuracy  macro avg  weighted avg\n",
      "precision       1.0     1.0    1.0       1.0        1.0           1.0\n",
      "recall          1.0     1.0    1.0       1.0        1.0           1.0\n",
      "f1-score        1.0     1.0    1.0       1.0        1.0           1.0\n",
      "support        14.0    14.0   14.0       1.0       42.0          42.0\n",
      "Accuracy: 72.22%\n",
      "---\n",
      "---\n",
      "           business  sports     world  accuracy  macro avg  weighted avg\n",
      "precision  0.666667     1.0  0.555556  0.722222   0.740741      0.740741\n",
      "recall     0.333333     1.0  0.833333  0.722222   0.722222      0.722222\n",
      "f1-score   0.444444     1.0  0.666667  0.722222   0.703704      0.703704\n",
      "support    6.000000     6.0  6.000000  0.722222  18.000000     18.000000\n"
     ]
    }
   ],
   "source": [
    "train_class_report, validate_class_report = model_words(CountVectorizer, RandomForestClassifier(n_estimators=75, random_state=123), (1,1), train, validate, target, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d3e5c-b506-4bba-b5a8-7a73eb17abed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
